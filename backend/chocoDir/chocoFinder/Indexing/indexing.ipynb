{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "# Revert SSL configuration to default\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl.create_default_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Specify the directory path relative to the notebook location\n",
    "data_dir = os.path.abspath(\"./../chocolate_crawler/Crawled/\")\n",
    "\n",
    "# List of JSON files\n",
    "json_files = ['laderach.json', 'spruengli.json', 'maxchocolatier.json']\n",
    "\n",
    "# Initialize an empty list to store data from all JSON files\n",
    "all_data = []\n",
    "\n",
    "# Load data from each JSON file\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(data_dir, json_file)\n",
    "\n",
    "    print(f\"Loading data from {json_path}\")\n",
    "\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            all_data.extend(data)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {json_path}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in {json_path}: {e}\")\n",
    "\n",
    "\n",
    "# Create an index\n",
    "idx = ['d' + str(i + 1) for i in range(len(all_data))]\n",
    "\n",
    "\n",
    "# Extract relevant information\n",
    "titles = [item.get('title', '') for item in all_data]\n",
    "descriptions = [item.get('description', '') for item in all_data]\n",
    "ingredients = [item.get('ingredients', '') for item in all_data]\n",
    "allergens = [item.get('allergens', '') for item in all_data]\n",
    "prices = [item.get('price', '') for item in all_data]\n",
    "\n",
    "# Create a DataFrame\n",
    "docs_df = pd.DataFrame(np.column_stack((idx, titles, descriptions, ingredients, allergens, prices)),\n",
    "                       columns=['docno', 'title', 'description', 'ingredients', 'allergens', 'price'])\n",
    "\n",
    "\n",
    "\n",
    "docs_df.to_csv(\"index/chocolate.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = pt.DFIndexer(\"./index\", overwrite=True)\n",
    "index_ref = indexer.index(docs_df[\"description\"], docs_df[\"docno\"])\n",
    "index_ref.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh index/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "type(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kv in index.getLexicon():\n",
    "  print(\"%s  -> %s \" % (kv.getKey(), kv.getValue().toString()  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(index.getLexicon()[\"document\"].toString())\n",
    "# print(index.getLexicon()[\"first\"].toString())\n",
    "# print(index.getLexicon()[\"topic\"].toString())\n",
    "# print(index.getLexicon()[\"unknown\"].toString())\n",
    "\n",
    "for kv in index.getLexicon() :\n",
    "  print(kv.getKey())\n",
    "  print(index.getLexicon()[kv.getKey()].toString())\n",
    "  print('**************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ = 'chocolate'\n",
    "pointer = index.getLexicon()[word_]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    print(posting.toString() + \" doclen=%d\" % posting.getDocumentLength())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = pt.BatchRetrieve(index, wmodel=\"BM25\") #Alternative Models: \"TF_IDF\", \"BM25\"\n",
    "br.search(\"dark chocolate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br.search(\"truffle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
